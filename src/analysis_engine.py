import cv2
import numpy as np
import os
import csv
import json
import tempfile
import subprocess
from typing import List, Dict, Any

# Services used to persist results (import here to avoid circular imports in other modules)
from services.analysis_report_service import AnalysisReportService
from services.player_match_statistics_service import PlayerMatchStatisticsService


class FootballAnalyzer:
    """Light wrapper for single-image analysis.

    Note: The heavy video analysis is delegated to the C++ `test_runner` binary.
    """
    def __init__(self, model_path: str = 'yolov8l.pt'):
        # Still allow a Python-based analyzer for quick single-image ops.
        print(f"Initializing analyzer (python wrapper) with model (placeholder): {model_path}")
        self.model_path = model_path

    def analyze_single_image(self, image):
        """Analyzes a single image for player and ball detection.

        This remains a lightweight placeholder. For full-video analysis the
        backend will call the high-performance C++ binary.
        """
        print("Analyzing single image (placeholder)...")
        return [
            {"box": [100, 150, 50, 50], "label": "player", "confidence": 0.95, "color": (0, 255, 0)},
            {"box": [200, 250, 25, 25], "label": "ball", "confidence": 0.88, "color": (255, 255, 255)},
        ]


def _parse_player_metrics_csv(csv_path: str) -> List[Dict[str, Any]]:
    """Parse `player_metrics.csv` generated by the C++ tool.

    Returns a list of dicts with keys matching PlayerMatchStatisticsCreate fields
    plus frame/player_id info.
    """
    results = []
    if not os.path.exists(csv_path):
        return results
    with open(csv_path, newline='') as csvfile:
        reader = csv.DictReader(csvfile)
        for row in reader:
            # Convert numeric fields when possible (defensive)
            converted = {}
            for k, v in row.items():
                if v is None or v == '':
                    converted[k] = None
                    continue
                # Try int then float else keep string
                try:
                    converted[k] = int(v)
                    continue
                except Exception:
                    pass
                try:
                    converted[k] = float(v)
                    continue
                except Exception:
                    converted[k] = v
            results.append(converted)
    return results


def _parse_ball_metrics_csv(csv_path: str) -> List[Dict[str, Any]]:
    # Similar parsing for ball metrics
    return _parse_player_metrics_csv(csv_path)


def analyze_football_match(video_path: str, db_connection, match_id: str = '') -> Dict[str, Any]:
    """Run the C++ analyzer on `video_path`, parse outputs and persist to DB.

    Expected environment variables to configure paths:
      - TEST_RUNNER_PATH: path to C++ binary (default: ./build/test_runner)
      - MODEL_PATH: path to ONNX model (optional)
      - CALIB_PATH: path to calibration.yaml (optional)

    The C++ binary must output `player_metrics.csv` and `ball_metrics.csv` in the output dir.
    """
    # Prefer an explicit env override
    test_runner = os.environ.get('TEST_RUNNER_PATH', '')
    model_path = os.environ.get('MODEL_PATH', '')
    calib_path = os.environ.get('CALIB_PATH', '')

    # If not provided, look for sibling AI repo and its built binary
    if not test_runner:
        sibling_runner = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', 'football-analyset-ai-model-main', 'build', 'test_runner'))
        if os.path.exists(sibling_runner):
            test_runner = sibling_runner
        else:
            # Also check top-level relative path (when running from project root)
            sibling_runner2 = os.path.abspath(os.path.join(os.getcwd(), 'football-analyset-ai-model-main', 'build', 'test_runner'))
            if os.path.exists(sibling_runner2):
                test_runner = sibling_runner2

    # If model/calibration paths not specified, try sibling repo defaults
    if not model_path:
        candidate = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', 'football-analyset-ai-model-main', 'yolov8m.onnx'))
        if os.path.exists(candidate):
            model_path = candidate
    if not calib_path:
        candidate_calib = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', 'football-analyset-ai-model-main', 'calibration.yaml'))
        if os.path.exists(candidate_calib):
            calib_path = candidate_calib

    if not test_runner or not os.path.exists(test_runner):
        raise FileNotFoundError(f"C++ analyzer binary not found. Checked TEST_RUNNER_PATH and sibling repo; tried: {test_runner}")

    # Prepare a temporary output directory for CSVs
    with tempfile.TemporaryDirectory() as out_dir:
        cmd: List[str] = [test_runner, '--video', video_path, '--output-dir', out_dir]
        if model_path:
            cmd += ['--model', model_path]
        if calib_path:
            cmd += ['--calib', calib_path]

        # Run the C++ analyzer (blocking). Consider making this async in future.
        try:
            print(f"Running C++ analyzer: {' '.join(cmd)}")
            completed = subprocess.run(cmd, check=True, capture_output=True, text=True, timeout=60*60)
            print('Analyzer stdout:', completed.stdout[:1000])
            print('Analyzer stderr:', completed.stderr[:1000])
        except subprocess.CalledProcessError as e:
            print('Analyzer failed:', e.stderr)
            raise
        except subprocess.TimeoutExpired:
            raise RuntimeError('C++ analyzer timed out')

        # Parse CSV outputs
        player_csv = os.path.join(out_dir, 'player_metrics.csv')
        ball_csv = os.path.join(out_dir, 'ball_metrics.csv')

        player_rows = _parse_player_metrics_csv(player_csv)
        ball_rows = _parse_ball_metrics_csv(ball_csv)

        # Persist results to DB using helper
        try:
            parse_and_persist_results(out_dir, db_connection, match_id)
        except Exception as e:
            print('Warning: error while persisting results:', e)

        # Build a JSON-friendly summary to return to client
        summary_stats = {
            'players_detected': len(set([r.get('player_id') for r in player_rows if r.get('player_id') is not None])),
            'player_rows': len(player_rows),
            'ball_rows': len(ball_rows),
        }

        return {
            'message': 'Analysis complete',
            'video_path': video_path,
            'summary_stats': summary_stats,
            'player_rows_sample': player_rows[:5],
            'ball_rows_sample': ball_rows[:5]
        }


def parse_and_persist_results(output_dir: str, db_connection, match_id: str = '') -> Dict[str, Any]:
    """Parse CSVs in `output_dir` and persist into DB. Returns summary dict.

    This helper allows the backend or a smoke-test to persist existing CSVs without
    requiring the analyzer to run in the same process.
    """
    player_csv = os.path.join(output_dir, 'player_metrics.csv')
    ball_csv = os.path.join(output_dir, 'ball_metrics.csv')

    player_rows = _parse_player_metrics_csv(player_csv)
    ball_rows = _parse_ball_metrics_csv(ball_csv)

    ar_service = AnalysisReportService(db_connection)
    pms_service = PlayerMatchStatisticsService(db_connection)

    summary = {
        'player_rows': len(player_rows),
        'ball_rows': len(ball_rows),
    }

    report_create = type('R', (), {})()
    report_create.match_id = match_id or ''
    report_create.report_type = 'full_match_analysis'
    report_create.report_data = summary
    report_create.generated_by = 'c++-analyzer'

    try:
        ar_service.create_analysis_report(report_create, [])
    except Exception as e:
        print('Warning: failed to persist analysis report:', e)

    for row in player_rows:
        stats = type('S', (), {})()
        stats.match_id = match_id or row.get('match_id', '')
        stats.player_id = str(row.get('player_id', row.get('id', 'unknown')))
        stats.minutes_played = int(row.get('minutes_played', 0) or 0)
        stats.shots = int(row.get('shots', 0) or 0)
        stats.shots_on_target = int(row.get('shots_on_target', 0) or 0)
        stats.passes = int(row.get('passes', 0) or 0)
        stats.accurate_passes = int(row.get('accurate_passes', 0) or 0)
        stats.tackles = int(row.get('tackles', 0) or 0)
        stats.interceptions = int(row.get('interceptions', 0) or 0)
        stats.clearances = int(row.get('clearances', 0) or 0)
        stats.saves = int(row.get('saves', 0) or 0)
        stats.fouls_committed = int(row.get('fouls_committed', 0) or 0)
        stats.fouls_suffered = int(row.get('fouls_suffered', 0) or 0)
        stats.offsides = int(row.get('offsides', 0) or 0)
        dist_m = float(row.get('total_distance_meters', 0) or 0)
        stats.distance_covered_km = dist_m / 1000.0
        stats.notes = json.dumps(row)
        stats.rating = float(row.get('rating', 0) or 0)

        try:
            pms_service.create_player_match_statistics(stats, [])
        except Exception as e:
            print('Warning: failed to persist player stats for', stats.player_id, e)

    return summary
